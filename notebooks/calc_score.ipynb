{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggan.pytorch.metrics.fid_score import calculate_fretchet\n",
    "from huggan.pytorch.metrics.inception import InceptionV3\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import torch\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo import load_model,generate,get_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_size=100\n",
    "model= InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=get_train_data()\n",
    "images_real = [to_tensor(ex.resize((512,512))) for ex in dataset[\"image\"][:calc_size]]\n",
    "images_real = torch.stack(images_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='ceyda/butterfly_cropped_uniq1K_512'\n",
    "# git rev-list main --first-parent\n",
    "versions=[\n",
    "    \"95a9596a1e47e2419c9bd5252d809eecb14fdcf4\"\n",
    "\"0738c09d1c4bde9bad9ff1800c639d9d50abb2d8\",\n",
    "\"e30e46e5ecbdc08aa7817aad35f468b34fc6aa43\",\n",
    "\"a61360529d4ce4b848b9dcf71f3100f8f0746630\",\n",
    "\"9af3333573664cc8654f6643f373d1ac0d769173\",\n",
    "\"406edbcc87643ae935238f430a21309e646b8c31\",\n",
    "\"54a7a0103796a4d6a242d2fdddad40814f9f48ba\",\n",
    "\"0edac54b81958b82ce9fd5c1f688c33ac8e4f223\",\n",
    "\"4aa71c62b3bcd4fe0d79190a069e0a16fe84838d\",\n",
    "\"3f3fe29048a5ce3de7b0cb2c1a03194a123ef276\",\n",
    "\"57d36a15546909557d9f967f47713236c8288838\",\n",
    "\"ed35ab2acdf9281cc2d38a136ce76cc714e474d8\",\n",
    "\"94a20acf6ea4fbadca04baaa62cdbe3d77823040\",\n",
    "\"afeb8691aa04c4114a7c4a323a9b2d3938f13995\",\n",
    "\"4ed1c58c2db77e7b68a9737261046959b4e2a5ca\",\n",
    "\"5498b1de2c523a70f89a8a7f36f344a7938ec53c\",\n",
    "\"ea571e51e052025f5a3bc780c86589530eaf0e7c\",\n",
    "\"77ca720fab77439ecea6b8c98c284c4569482741\",\n",
    "\"7c0344c29455eedfd50c9f44b04e2a7d28bb7cf8\",\n",
    "\"711389bf73d0be68065032a01efb82c937e44ea1\",\n",
    "\"0d0e100d32f505a74edc788d6e21a43d17baf2e4\",\n",
    "\"f8f1f001f031c0f72519fdfb065eccd8b730aaf0\",\n",
    "\"fd170b285c658f271ae73632a55c12d1ff6590da\",\n",
    "\"e41125be4b1994516cf56eee966af252a17b3e2e\",\n",
    "\"fc57f489f38b60a52b9d197439466e549ebed40a\",\n",
    "\"9265be8a24a3a1fa95fc9533673cf0fbb1abc3f5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,version in enumerate(versions):\n",
    "    run=wandb.init(project='butterfly-gan-fid',reinit=True,name=f\"{v}-{version}\",resume=True)\n",
    "    # model_name='ceyda/butterfly_512_base'\n",
    "    gan = load_model(model_name,version)\n",
    "    batch_size=4\n",
    "    images_fake = []\n",
    "    for e in range(int(calc_size/batch_size)):\n",
    "        gs = generate(gan,batch_size)\n",
    "        for i,im in enumerate(gs):\n",
    "            img=Image.fromarray(im)\n",
    "            # img.save(f\"./assets/outputs/{e*batch_size+i}_fake.jpg\")\n",
    "            images_fake.append(to_tensor(img))\n",
    "    # images_fake = [to_tensor(Image.open(f\"./assets/outputs/{i}_fake.jpg\")) for i in range(calc_size)]\n",
    "    images_fake = torch.stack(images_fake)\n",
    "    score=calculate_fretchet(images_real, images_fake, model)\n",
    "    print(f\"{v}-{version}: {score}\")\n",
    "    wandb.log({\"examples\": wandb.Image(make_grid(images_fake,nrow=4))})\n",
    "    wandb.log({\"fid_score\":score})\n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_fretchet(images_real, images_fake, model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
